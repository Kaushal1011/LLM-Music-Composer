# ğŸ¹ LLM-Composer

Generate, **hear**, and **see** fresh four-bar melodies just by _describing a vibe_ in chat.  
Built with **Next.js 15**, **React 19**, **TypeScript**, and **Tone.js**.

## Author's Note

For the most part I made this to learn how nextjs works and how I can build an ai workflow with wordware. follow the generic   `pnpm install` and `pnpm dev` commands to get started. I have not added any extra features or anything like that. I just wanted to see how the whole thing works. 

the interface is very simple and easy to use. url should be `http://localhost:3000/dashboard` after running the above commands.

I tried exporting midi and sound and creating a real song from it in a DAW turns out it works pretty well. I used FL Studio to create a song from it. I will be adding a video of the same in the future. It does need tweaking and some extra work but it is a good start. 

## [SONG on Soundcloud](https://on.soundcloud.com/HtZ3oGpd6uEYyf2x7) 

The melody and bassline notes were created from this app and then tweaked and mixed.

Working Demo looks like this: ![Demo](./image.png)

(THIS README WAS AUTOGENERATE BEYOND THIS POINT BY GPT-4 in a HURRY)



---

## âœ¨ Features

|                             | What it does                                                                          |
| --------------------------- | ------------------------------------------------------------------------------------- |
| ğŸ’¬ **Chat-driven creation**  | Type a style prompt (â€œlo-fi chill in Dâ™­â€) &rarr; LLM returns a quantised melody JSON. |
| ğŸ”Š **Instant playback**      | Melody is mapped to Tone.js events and played with a selectable synth preset.         |
| ğŸ¹ **Piano-roll visualiser** | Notes render in a lightweight SVG roll that scrolls in time.                          |
| ğŸ’¾ **One-click MIDI export** | Save the generated loop and drop it into any DAW.                                     |
| ğŸ” **History panel**         | Scroll back through every prompt/response and replay any idea.                        |

---

## ğŸš€ Quick start

```bash
git clone https://github.com/Kaushal1011/LLM-Music-Composer.git
cd LLM-Music-Composer

pnpm install            # or npm i / yarn
cp .exampleenv .env     # add your keys (see below)
pnpm dev                # http://localhost:3000
````

> **Node â‰¥ 18** is recommended (Next 14â€²s minimum).

---

## ğŸ”‘ Environment variables

| Key                | Purpose                                             |
| ------------------ | --------------------------------------------------- |
| `WORDWARE_API_KEY` | Auth token for the Wordware LLM endpoint.           |
| `APP_ID`           | Wordware application-ID you created for your model. |

APP_ID for my own workflow that generated the melody is `9841a2bd-2263-49ea-b96d-9500bb48350b`.


You can generate both inside your Wordware dashboard.

---

## ğŸ“‚ Project layout (Approximate)

```
.
â”œâ”€ .next/               # Build output (auto-generated)
â”œâ”€ app/                 # Next.js 14 App-router pages & routes
â”‚  â”œâ”€ layout.tsx        # Root layout â€“ providers & fonts
â”‚  â””â”€ page.tsx          # Chat + piano-roll UI
â”œâ”€ components/          # Re-usable UI pieces
â”‚  â”œâ”€ chat/             # ChatLog, ChatInput
â”‚  â””â”€ visualizer/       # PianoRoll renderer
â”œâ”€ lib/
â”‚  â”œâ”€ melodyPrompt.ts   # System prompt & guardrails for the LLM
â”‚  â”œâ”€ toneMapper.ts     # JSON â†’ Tone.Part event conversion
â”‚  â””â”€ playMelody.ts     # Tone.js synth factory & transport control
â”œâ”€ public/              # Static assets (icons, demo GIF, â€¦)
â”œâ”€ .exampleenv          # Template env file
â”œâ”€ next.config.ts       # Custom Next.js config (SWC minify + experimental opts)
â”œâ”€ package.json         # Scripts & dependencies
â””â”€ README.md            # You are here
```

---

## ğŸ—  How it works 

1. **Prompt** â€“ User types a mood/genre in the chat box.
2. **LLM call** â€“ `melodyPrompt.ts` sends a *system prompt* + user text to Wordware and expects pure JSON like:<br>`[ [0,"C4",0,1], â€¦ ]`
3. **Mapping** â€“ `toneMapper.ts` wraps the tuples into Tone.jsâ€friendly `EventTuple`s.
4. **Playback** â€“ `playMelody.ts` spins up a `PolySynth`, schedules a `Tone.Part`, and starts `Tone.Transport`.
5. **Visual** â€“ The same tuples render as SVG blocks inside `PianoRoll.tsx` so what you hear is what you see.

---

## ğŸ“œ NPM scripts

| Command      | What it does                                  |
| ------------ | --------------------------------------------- |
| `pnpm dev`   | Run dev server with hot reload.               |
| `pnpm build` | Build for production (`.next/`).              |
| `pnpm start` | Start the compiled app (needs `build` first). |
| `pnpm lint`  | ESLint + Next linting.                        |

---

## ğŸš¢ Deployment

Any place that runs a standard Next.js 14 build will work (Vercel, Netlify, Fly, Render, self-host).
On **Vercel**:

1. Push the repo to GitHub/GitLab.
2. Add project â†’ import repo â†’ *Environment Variables* â†’ paste `WORDWARE_API_KEY`, `APP_ID`.
3. Hit **Deploy**.  Vercel detects Next.js and does the rest.

---

## ğŸ›£  Roadmap

* Polyphonic & chord generation
* Tempo / swing controls
* Preset selector in the UI
* Download as WAV/MP3
* Persistent user accounts & cloud melody library

---

## ğŸ¤ Contributing

Pull requests are welcome! Please:

1. Fork the repo, create a feature branch off `main`.
2. Keep commits small and descriptive.
3. Run `pnpm lint` before opening the PR.

---

## ğŸ“„ License

MIT â€” do what you want, just keep the header.

---

> Happy composing! ğŸ§




This is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

You can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.

This project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.
